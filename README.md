# ðŸ§  AI-Powered Subjective Answer Evaluation System

An AI-based system that automates the evaluation of handwritten student answersheets using OCR, NLP, and deep learning. The project supports end-to-end processing of scanned PDFs, model answer generation, semantic scoring, and diagram analysis.

---

## ðŸš€ Features

- âœ… Extracts text from handwritten answers using **TrOCR**
- âœ… Scores student responses using **semantic similarity (BERT embeddings)**
- âœ… Supports **AI-generated model answers**
- âœ… Automatically detects and evaluates **diagrams** using **OpenCV**
- âœ… Handles full **PDF processing workflow**
- âœ… Displays real-time feedback and scoring
- âœ… Modular architecture for easy extension

---

## ðŸ§° Tech Stack

### ðŸ’» Core Technologies
- **Python**
- **FastAPI** / Flask
- **Streamlit** (Dashboard UI)

### ðŸ§  AI & NLP
- [x] Hugging Face Transformers
- [x] Sentence Transformers (`paraphrase-mpnet-base-v2`)
- [x] TrOCR (`microsoft/trocr-base-handwritten`)
- [x] PyTorch
- [x] spaCy, NLTK

### ðŸ–‹ OCR & Image Processing
- TrOCR
- pytesseract (fallback)
- OpenCV
- pdf2image
- PIL (Pillow)

### ðŸ“Š Data & Visualization
- Pandas
- NumPy
- Matplotlib

---

<pre> ```plaintext ðŸ“‚ Project Structure . â”œâ”€â”€ pipeline.py # Main script: PDF â†’ text + diagram extraction â”œâ”€â”€ model_answer_generator.py # Generates AI model answers (optional) â”œâ”€â”€ scoring_module.py # Computes similarity-based scores â”œâ”€â”€ output/ # Extracted page images and diagrams â”œâ”€â”€ sample_answersheet.pdf # Example input file â”œâ”€â”€ requirements.txt # All dependencies â”œâ”€â”€ templates/ # (If using Flask/Streamlit) â”œâ”€â”€ static/ # (CSS/JS assets if any) ``` </pre>


